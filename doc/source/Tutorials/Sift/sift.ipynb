{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT image alignment tutorial\n",
    "\n",
    "SIFT (Scale-Invariant Feature Transform) is an algorithm developped by David Lowe in 1999. It is a worldwide reference for image alignment and object recognition. The robustness of this method enables to detect features at different scales, angles and illumination of a scene. Silx provides an implementation of SIFT in OpenCL, meaning that it can run on Graphics Processing Units and Central Processing Units as well. Interest points are detected in the image, then data structures called *descriptors* are built to be characteristic of the scene, so that two different images of the same scene have similar descriptors. They are robust to transformations like translation, rotation, rescaling and illumination change, which make SIFT interesting for image stitching. In the fist stage, descriptors are computed from the input images. Then, they are compared to determine the geometric transformation to apply in order to align the images. This implementation can run on most graphic cards and CPU, making it usable on many setups. OpenCL processes are handled from Python with PyOpenCL, a module to access OpenCL parallel computation API.\n",
    "\n",
    "This tutuorial explains the three subsequent steps:\n",
    "\n",
    "* keypoint extraction\n",
    "* Keypoint matching\n",
    "* image alignment\n",
    "\n",
    "All the tutorial has been made using the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display test image\n",
    "import scipy.misc\n",
    "image = scipy.misc.ascent()\n",
    "imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialization of the sift object is time consuming: it compiles all the code.\n",
    "import os \n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"0\" #set to 1 to see the compilation going on\n",
    "from silx.image import sift\n",
    "%time sift_ocl = sift.SiftPlan(template=image, devicetype=\"CPU\") #switch to GPU to test your graphics card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Time for calculating the keypoints on one image of size %sx%s\"%image.shape)\n",
    "%time keypoints = sift_ocl(image)\n",
    "print(\"Number of keypoints: %s\"%len(keypoints))\n",
    "print(\"Keypoint content:\")\n",
    "print(keypoints.dtype)\n",
    "print(\"x: %.3f \\t y: %.3f \\t sigma: %.3f \\t angle: %.3f\" % \n",
    "      (keypoints[-1].x,keypoints[-1].y,keypoints[-1].scale,keypoints[-1].angle))\n",
    "print(\"descriptor:\")\n",
    "print(keypoints[-1].desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Overlay keypoints on the image:\n",
    "imshow(image, cmap=\"gray\")\n",
    "plot(keypoints[:].x, keypoints[:].y,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Diplaying keypoints by scale:\n",
    "hist(keypoints[:].scale, 100)\n",
    "xlabel(\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One can see 2 groups of keypoints: <12 and >12. Let's display them using colors.\n",
    "S = 8\n",
    "L = 20\n",
    "tiny = keypoints[keypoints[:].scale<S]\n",
    "small = keypoints[numpy.logical_and(keypoints[:].scale<L,keypoints[:].scale>=S)]\n",
    "bigger = keypoints[keypoints[:].scale>=L]\n",
    "imshow(image, cmap=\"gray\")\n",
    "plot(tiny[:].x, tiny[:].y,\".g\", label=\"tiny\")\n",
    "plot(small[:].x, small[:].y,\".b\", label=\"small\")\n",
    "plot(bigger[:].x, bigger[:].y,\".r\", label=\"large\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image matching and alignment\n",
    "\n",
    "Matching can also be performed on the device (GPU) as every single keypoint from an image needs to be compared with all\n",
    "keypoints from the second image.\n",
    "\n",
    "In this simple example we will simple offset the first image by a few pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shifted = numpy.zeros_like(image)\n",
    "shifted[5:,8:] = image[:-5, :-8]\n",
    "shifted_points = sift_ocl(shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time mp = sift.MatchPlan()\n",
    "%time match = mp.match(keypoints, shifted_points)\n",
    "print(\"Number of Keypoints with for image 1 : %i, For image 2 : %i, Matching keypoints: %i\" % (kp1.size, kp2.size, match.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- David G. Lowe, Distinctive image features from scale-invariant keypoints, International Journal of Computer Vision, vol. 60, no 2, 2004, p. 91â€“110 - \"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
